<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <title>Beyond Reality Face SDK - BRFv5 - Face Tracking for Browser/JavaScript - Minimal Webcam Example</title>
    <script src="Build/UnityLoader.js"></script>
    <link rel="stylesheet" href="style.css">

    <style>
        html,
        body {
            width: 100%;
            height: 100%;
            background-color: #ffffff;
            margin: 0;
            padding: 0;
            overflow: hidden;
        }

        .abs {
            position: absolute
        }

        .vh {
            visibility: hidden
        }
    </style>
</head>

<body>
    <canvas id="myCanvas">
        Your browser does not support the canvas element.
    </canvas>
    <div id='container'>
        <video id="_webcam" style="display: none;" playsinline></video>
        <canvas id="_imageData"></canvas>
    </div>
    <div id="unityContainer"> </div>

    <br><br>
    <div id="btn">
        <button onclick="load()">
            load
        </button>
        <button onclick="pass()">
            pass
        </button>
        <br>
        <input id="xxx" type="text" placeholder="Stiffness Force">
        <br>
        <input id="yyy" type="text" placeholder="Drag Force">
        <br>

        <br>
        <button onclick="poss()">Dangling</button>
        <script>

            function pass() {
                console.log("clicked");
                var s = JSON.parse('{"positionForRight":{"x": 0,"y": 0,"z": 0},"positionForLeft":{"x": 0,"y": 0,"z": 0},"scaleForLeft":{"x": 3.5,"y": 3.5,"z": 3.5},"scaleForRight":{"x": 3.5,"y": 3.5,"z": 3.5}}');
                console.log(s);
                unity.SendMessage('ObjectContainer', 'TrsnsformObject', JSON.stringify(s));
            }

            function load() {
                unity.SendMessage('ObjectContainer', 'LoadContent', "https://mirrar.s3.ap-south-1.amazonaws.com/amazingabhishek/AssetBundles/righter");
            }

            function poss() {
                let p = {
                    x: document.getElementById("xxx").value,
                    y: document.getElementById("yyy").value,
                }

                unity.SendMessage('ObjectContainer', 'SetMovement', JSON.stringify(p));
            }
        </script>
    </div>

    <script>
        var unity = UnityLoader.instantiate("unityContainer", "Build/WebGL.json");
    </script>

    <script type="module">

        import { brfv5 } from './js/brfv5/brfv5__init.js'
        import { loadBRFv5Model } from './js/brfv5/brfv5__init.js'
        import { configureCameraInput } from './js/brfv5/brfv5__configure.js'
        import { configureFaceTracking } from './js/brfv5/brfv5__configure.js'
        import { configureNumFacesToTrack } from './js/brfv5/brfv5__configure.js'
        import { startCamera } from './js/utils/utils__camera.js'
        import { drawInputMirrored } from './js/utils/utils__canvas.js'

        import {
            mountPNGOverlay, setSizePNGOverlay, hidePNGOverlay,
            loadPNGOverlays, updateByFace
        } from './js/ui/ui__overlay__png.js'
        import { ScaleMode } from './js/utils/utils__resize.js'

        const _images = [
            {
                // url: './assets/brfv5_img_lion.png', alpha: 0.66,
                // scale: 0.66, xOffset: 0.5, yOffset: 0.40
            },
            {
                // url: './assets/brfv5_img_glasses.png', alpha: 1.00,
                // scale: 0.25, xOffset: 0.5, yOffset: 0.45
            }
        ];

        mountPNGOverlay(document.getElementById('container'), ScaleMode.NO_SCALE)
        loadPNGOverlays(_images)

        const _appId = 'brfv5.browser.minimal.modules.pngoverlay' // (mandatory): 8 to 64 characters, a-z . 0-9 allowed

        const _webcam = document.getElementById('_webcam')
        const _imageData = document.getElementById('_imageData')

        // Those variables will be retrieved from the stream and the library.
        let _brfv5Manager = null
        let _brfv5Config = null
        let _width = 0
        let _height = 0

        // loadBRFv5Model and openCamera are being done simultaneously thanks to Promises. Both call
        // configureTracking which only gets executed once both Promises were successful. Once configured
        // trackFaces will do the tracking work and draw the results.

        startCamera(_webcam, { width: 640, height: 480, frameRate: 30, facingMode: 'user' }).then(({ video }) => {

            console.log('openCamera: done: ' + video.videoWidth + 'x' + video.videoHeight)

            _width = video.videoWidth
            _height = video.videoHeight

            _imageData.width = _width
            _imageData.height = _height

            const container = document.getElementById("container")
            container.style.width = _width + 'px'
            container.style.height = _height + 'px'

            setSizePNGOverlay(_width, _height)

            configureTracking()

        }).catch((e) => { if (e) { console.error('Camera failed: ', e) } })

        loadBRFv5Model('68l', 8, './js/brfv5/models/', _appId,
            (progress) => { console.log(progress) }).then(({ brfv5Manager, brfv5Config }) => {

                console.log('loadBRFv5Model: done')

                _brfv5Manager = brfv5Manager
                _brfv5Config = brfv5Config

                configureTracking()

            }).catch((e) => { console.error('BRFv5 failed: ', e) })

        const configureTracking = () => {

            if (_brfv5Config !== null && _width > 0) {

                configureCameraInput(_brfv5Config, _width, _height)
                configureNumFacesToTrack(_brfv5Config, 1)
                configureFaceTracking(_brfv5Config, 3, true)

                _brfv5Manager.configure(_brfv5Config)

                trackFaces()
            }
        }

        const trackFaces = () => {

            if (!_brfv5Manager || !_brfv5Config || !_imageData) { return }

            const ctx = _imageData.getContext('2d')

            drawInputMirrored(ctx, _width, _height, _webcam)

            hidePNGOverlay()

            _brfv5Manager.update(ctx.getImageData(0, 0, _width, _height))

            const faces = _brfv5Manager.getFaces();
            unity.SendMessage('ObjectContainer', 'setScale', 0.1);
            // unity.SendMessage('ObjectContainer', 'screenRatio', 1);
            var canvas = document.getElementById("myCanvas");
            var unityContainer = document.getElementById("unityContainer");
            canvas.setAttribute('width', '640px');
            canvas.setAttribute('height', '480px');
            unityContainer.style.width = "640px"
            unityContainer.style.height = "480px"
            var context = canvas.getContext("2d");
            context.font = "7px Arial";

            for (let i = 0; i < faces.length; i++) {

                // console.log(`canvas: w: ${canvas.width}, h: ${canvas.height}`)
                //width: 640, height: 480
                let left = {
                    x: parseFloat((faces[i].landmarks[2].x - 320) / 42),
                    y: parseFloat(((240 - faces[i].landmarks[2].y) / 42) + 1),
                    z: 0
                };

                let right = {
                    x: parseFloat((faces[i].landmarks[14].x - 320) / 42),
                    y: parseFloat(((240 - faces[i].landmarks[14].y) / 42) + 1),
                    z: 0
                };

                let finalObject = {
                    positionForRight: right,
                    positionForLeft: left,
                    scaleForLeft: {
                        x: 2, y: 2, z: 2
                    },
                    scaleForRight: {
                        x: 2, y: 2, z: 2
                    }
                }

                let pos = {
                    vectors: []
                };
                context.clearRect(0, 0, canvas.width, canvas.height);

                for (let j = 0; j < faces[i].landmarks.length; j++) {

                    context.fillText(j, faces[i].landmarks[j].x, faces[i].landmarks[j].y);
                    pos.vectors.push({
                        x: parseFloat(((faces[i].landmarks[j].x) - 320) / 42),
                        y: parseFloat(((240 - (faces[i].landmarks[j].y)) / 42) + 1),
                        // x: parseFloat(((faces[i].landmarks[j].x) / 64)),
                        // y: parseFloat(((240 - faces[i].landmarks[j].y) / 64)),
                        z: 0
                    })
                }
                // console.log(`this is pos ${pos.vectors[0].x} ${pos.vectors[0].y}`)
                // unity.SendMessage('ObjectContainer', 'printMask', JSON.stringify(pos));
                unity.SendMessage('ObjectContainer', 'TestSubject', JSON.stringify(right));
                unity.SendMessage('ObjectContainer', 'TestSubject2', JSON.stringify(left));
                unity.SendMessage('ObjectContainer', 'TrsnsformObject', JSON.stringify(finalObject));

                const face = faces[i]
                if (face.state === brfv5.BRFv5State.FACE_TRACKING) {
                    updateByFace(face, i, true)
                } else {
                    updateByFace(null, i, false)
                }
            }
            requestAnimationFrame(trackFaces)
        }
    </script>

</body>

</html>
